{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fecha</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "      <th>titulo</th>\n",
       "      <th>subtitular</th>\n",
       "      <th>cant_notas</th>\n",
       "      <th>politica</th>\n",
       "      <th>...</th>\n",
       "      <th>publicidad</th>\n",
       "      <th>contraportada</th>\n",
       "      <th>modelo</th>\n",
       "      <th>palabras_titulo</th>\n",
       "      <th>palabras_st</th>\n",
       "      <th>envio_total</th>\n",
       "      <th>cobrable</th>\n",
       "      <th>devuelto</th>\n",
       "      <th>vendido</th>\n",
       "      <th>total_paginas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010222nacional</td>\n",
       "      <td>2/1/2022</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>January</td>\n",
       "      <td>2022</td>\n",
       "      <td>nacional</td>\n",
       "      <td>celebracion lo lleva a la muerte</td>\n",
       "      <td>ya no llego a darles el abrazo a sus papas, en...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>modelo</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>94993</td>\n",
       "      <td>93185</td>\n",
       "      <td>11937</td>\n",
       "      <td>81248</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010322nacional</td>\n",
       "      <td>3/1/2022</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "      <td>2022</td>\n",
       "      <td>nacional</td>\n",
       "      <td>campeon historico</td>\n",
       "      <td>los toros suman su primer titulo de liga nacional</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>deporte</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>110810</td>\n",
       "      <td>108409</td>\n",
       "      <td>6740</td>\n",
       "      <td>101669</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>010422nacional</td>\n",
       "      <td>4/1/2022</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>January</td>\n",
       "      <td>2022</td>\n",
       "      <td>nacional</td>\n",
       "      <td>arde ensambladora</td>\n",
       "      <td>se destruyen miles de motos en amatitlan</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>nacionales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>97543</td>\n",
       "      <td>95151</td>\n",
       "      <td>8336</td>\n",
       "      <td>86815</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>010522nacional</td>\n",
       "      <td>5/1/2022</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "      <td>2022</td>\n",
       "      <td>nacional</td>\n",
       "      <td>balean albaniles</td>\n",
       "      <td>sicarios los esperaban en esquina del centro d...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>modelo</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>96234</td>\n",
       "      <td>93842</td>\n",
       "      <td>14682</td>\n",
       "      <td>79160</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010622nacional</td>\n",
       "      <td>6/1/2022</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>January</td>\n",
       "      <td>2022</td>\n",
       "      <td>nacional</td>\n",
       "      <td>feliz dia de reyes</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>modelo</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>96254</td>\n",
       "      <td>93851</td>\n",
       "      <td>9796</td>\n",
       "      <td>84055</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id     fecha        day    month  year    region  \\\n",
       "0  010222nacional  2/1/2022     Sunday  January  2022  nacional   \n",
       "1  010322nacional  3/1/2022     Monday  January  2022  nacional   \n",
       "2  010422nacional  4/1/2022    Tuesday  January  2022  nacional   \n",
       "3  010522nacional  5/1/2022  Wednesday  January  2022  nacional   \n",
       "4  010622nacional  6/1/2022   Thursday  January  2022  nacional   \n",
       "\n",
       "                             titulo  \\\n",
       "0  celebracion lo lleva a la muerte   \n",
       "1                 campeon historico   \n",
       "2                 arde ensambladora   \n",
       "3                  balean albaniles   \n",
       "4                feliz dia de reyes   \n",
       "\n",
       "                                          subtitular  cant_notas  politica  \\\n",
       "0  ya no llego a darles el abrazo a sus papas, en...           4         0   \n",
       "1  los toros suman su primer titulo de liga nacional           5         0   \n",
       "2           se destruyen miles de motos en amatitlan           4         0   \n",
       "3  sicarios los esperaban en esquina del centro d...           3         0   \n",
       "4                                                  -           1         0   \n",
       "\n",
       "   ...  publicidad  contraportada  modelo  palabras_titulo  palabras_st  \\\n",
       "0  ...           0         modelo       1                6           13   \n",
       "1  ...           1        deporte       1                2            9   \n",
       "2  ...           0     nacionales       1                2            7   \n",
       "3  ...           1         modelo       1                2           10   \n",
       "4  ...           0         modelo       1                4            1   \n",
       "\n",
       "   envio_total  cobrable  devuelto  vendido total_paginas  \n",
       "0        94993     93185     11937    81248            36  \n",
       "1       110810    108409      6740   101669            34  \n",
       "2        97543     95151      8336    86815            32  \n",
       "3        96234     93842     14682    79160            32  \n",
       "4        96254     93851      9796    84055            32  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar datos\n",
    "file_path = r'C:\\Users\\emisi\\OneDrive\\INCAE_Análisis de Datos, Innovación y Tecnología\\PAIT\\Nuestro Diario\\Bases de Datos\\Análisis de Bases de Datos\\DatosNacionales.csv'\n",
    "df = pd.read_csv(file_path, delimiter= ';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Gradient Boosted Trees con n_estimators=20, max_depth=5\n",
      "Entrenando Gradient Boosted Trees con n_estimators=20, max_depth=10\n",
      "Entrenando Gradient Boosted Trees con n_estimators=20, max_depth=15\n",
      "Entrenando Gradient Boosted Trees con n_estimators=20, max_depth=25\n",
      "Entrenando Gradient Boosted Trees con n_estimators=40, max_depth=5\n",
      "Entrenando Gradient Boosted Trees con n_estimators=40, max_depth=10\n",
      "Entrenando Gradient Boosted Trees con n_estimators=40, max_depth=15\n",
      "Entrenando Gradient Boosted Trees con n_estimators=40, max_depth=25\n",
      "Entrenando Gradient Boosted Trees con n_estimators=60, max_depth=5\n",
      "Entrenando Gradient Boosted Trees con n_estimators=60, max_depth=10\n",
      "Entrenando Gradient Boosted Trees con n_estimators=60, max_depth=15\n",
      "Entrenando Gradient Boosted Trees con n_estimators=60, max_depth=25\n",
      "Entrenando Gradient Boosted Trees con n_estimators=80, max_depth=5\n",
      "Entrenando Gradient Boosted Trees con n_estimators=80, max_depth=10\n",
      "Entrenando Gradient Boosted Trees con n_estimators=80, max_depth=15\n",
      "Entrenando Gradient Boosted Trees con n_estimators=80, max_depth=25\n",
      "Entrenando Gradient Boosted Trees con n_estimators=100, max_depth=5\n",
      "Entrenando Gradient Boosted Trees con n_estimators=100, max_depth=10\n",
      "Entrenando Gradient Boosted Trees con n_estimators=100, max_depth=15\n",
      "Entrenando Gradient Boosted Trees con n_estimators=100, max_depth=25\n",
      "\n",
      "Ranking de modelos por RMSE:\n",
      "    Number of Trees  Maximal Depth          RMSE  Absolute Error  \\\n",
      "17              100             10   7928.102944     5223.816580   \n",
      "13               80             10   7930.256971     5229.515850   \n",
      "9                60             10   7943.189476     5254.185776   \n",
      "5                40             10   7980.367862     5316.415215   \n",
      "1                20             10   8216.878367     5605.742167   \n",
      "18              100             15   8475.141101     5604.680585   \n",
      "14               80             15   8475.457846     5604.749674   \n",
      "10               60             15   8480.108273     5608.228263   \n",
      "6                40             15   8482.897359     5618.166127   \n",
      "2                20             15   8587.880726     5772.481852   \n",
      "16              100              5   8695.346845     5615.847696   \n",
      "12               80              5   8712.901633     5651.259844   \n",
      "8                60              5   8765.447331     5739.261780   \n",
      "4                40              5   8775.525402     5924.242428   \n",
      "0                20              5   9284.853968     6486.370688   \n",
      "3                20             25   9702.750396     6291.149922   \n",
      "7                40             25   9973.180937     6415.635246   \n",
      "11               60             25  10026.468152     6445.621591   \n",
      "15               80             25  10032.721000     6449.292316   \n",
      "19              100             25  10033.291943     6449.738190   \n",
      "\n",
      "    Relative Error (%)  Squared Error  Correlation Coefficient  \n",
      "17           16.254964   6.285482e+07                 0.803736  \n",
      "13           16.293217   6.288898e+07                 0.803625  \n",
      "9            16.347236   6.309426e+07                 0.802970  \n",
      "5            16.450271   6.368627e+07                 0.801344  \n",
      "1            17.240436   6.751709e+07                 0.795649  \n",
      "18           17.549012   7.182802e+07                 0.774714  \n",
      "14           17.550168   7.183339e+07                 0.774677  \n",
      "10           17.573885   7.191224e+07                 0.774338  \n",
      "6            17.681336   7.195955e+07                 0.773440  \n",
      "2            19.051572   7.375170e+07                 0.766070  \n",
      "16           18.658950   7.560906e+07                 0.758649  \n",
      "12           18.741572   7.591465e+07                 0.757533  \n",
      "8            18.973020   7.683307e+07                 0.754234  \n",
      "4            19.283247   7.700985e+07                 0.755153  \n",
      "0            20.998224   8.620851e+07                 0.732759  \n",
      "3            23.722095   9.414337e+07                 0.703481  \n",
      "7            23.132590   9.946434e+07                 0.707727  \n",
      "11           23.127722   1.005301e+08                 0.707704  \n",
      "15           23.128067   1.006555e+08                 0.707722  \n",
      "19           23.126596   1.006669e+08                 0.707734  \n",
      "\n",
      "Ranking de modelos por Error Absoluto:\n",
      "    Number of Trees  Maximal Depth          RMSE  Absolute Error  \\\n",
      "17              100             10   7928.102944     5223.816580   \n",
      "13               80             10   7930.256971     5229.515850   \n",
      "9                60             10   7943.189476     5254.185776   \n",
      "5                40             10   7980.367862     5316.415215   \n",
      "18              100             15   8475.141101     5604.680585   \n",
      "14               80             15   8475.457846     5604.749674   \n",
      "1                20             10   8216.878367     5605.742167   \n",
      "10               60             15   8480.108273     5608.228263   \n",
      "16              100              5   8695.346845     5615.847696   \n",
      "6                40             15   8482.897359     5618.166127   \n",
      "12               80              5   8712.901633     5651.259844   \n",
      "8                60              5   8765.447331     5739.261780   \n",
      "2                20             15   8587.880726     5772.481852   \n",
      "4                40              5   8775.525402     5924.242428   \n",
      "3                20             25   9702.750396     6291.149922   \n",
      "7                40             25   9973.180937     6415.635246   \n",
      "11               60             25  10026.468152     6445.621591   \n",
      "15               80             25  10032.721000     6449.292316   \n",
      "19              100             25  10033.291943     6449.738190   \n",
      "0                20              5   9284.853968     6486.370688   \n",
      "\n",
      "    Relative Error (%)  Squared Error  Correlation Coefficient  \n",
      "17           16.254964   6.285482e+07                 0.803736  \n",
      "13           16.293217   6.288898e+07                 0.803625  \n",
      "9            16.347236   6.309426e+07                 0.802970  \n",
      "5            16.450271   6.368627e+07                 0.801344  \n",
      "18           17.549012   7.182802e+07                 0.774714  \n",
      "14           17.550168   7.183339e+07                 0.774677  \n",
      "1            17.240436   6.751709e+07                 0.795649  \n",
      "10           17.573885   7.191224e+07                 0.774338  \n",
      "16           18.658950   7.560906e+07                 0.758649  \n",
      "6            17.681336   7.195955e+07                 0.773440  \n",
      "12           18.741572   7.591465e+07                 0.757533  \n",
      "8            18.973020   7.683307e+07                 0.754234  \n",
      "2            19.051572   7.375170e+07                 0.766070  \n",
      "4            19.283247   7.700985e+07                 0.755153  \n",
      "3            23.722095   9.414337e+07                 0.703481  \n",
      "7            23.132590   9.946434e+07                 0.707727  \n",
      "11           23.127722   1.005301e+08                 0.707704  \n",
      "15           23.128067   1.006555e+08                 0.707722  \n",
      "19           23.126596   1.006669e+08                 0.707734  \n",
      "0            20.998224   8.620851e+07                 0.732759  \n",
      "\n",
      "Ranking de modelos por R²:\n",
      "    Number of Trees  Maximal Depth          RMSE  Absolute Error  \\\n",
      "17              100             10   7928.102944     5223.816580   \n",
      "13               80             10   7930.256971     5229.515850   \n",
      "9                60             10   7943.189476     5254.185776   \n",
      "5                40             10   7980.367862     5316.415215   \n",
      "1                20             10   8216.878367     5605.742167   \n",
      "18              100             15   8475.141101     5604.680585   \n",
      "14               80             15   8475.457846     5604.749674   \n",
      "10               60             15   8480.108273     5608.228263   \n",
      "6                40             15   8482.897359     5618.166127   \n",
      "2                20             15   8587.880726     5772.481852   \n",
      "16              100              5   8695.346845     5615.847696   \n",
      "12               80              5   8712.901633     5651.259844   \n",
      "4                40              5   8775.525402     5924.242428   \n",
      "8                60              5   8765.447331     5739.261780   \n",
      "0                20              5   9284.853968     6486.370688   \n",
      "19              100             25  10033.291943     6449.738190   \n",
      "7                40             25   9973.180937     6415.635246   \n",
      "15               80             25  10032.721000     6449.292316   \n",
      "11               60             25  10026.468152     6445.621591   \n",
      "3                20             25   9702.750396     6291.149922   \n",
      "\n",
      "    Relative Error (%)  Squared Error  Correlation Coefficient  \n",
      "17           16.254964   6.285482e+07                 0.803736  \n",
      "13           16.293217   6.288898e+07                 0.803625  \n",
      "9            16.347236   6.309426e+07                 0.802970  \n",
      "5            16.450271   6.368627e+07                 0.801344  \n",
      "1            17.240436   6.751709e+07                 0.795649  \n",
      "18           17.549012   7.182802e+07                 0.774714  \n",
      "14           17.550168   7.183339e+07                 0.774677  \n",
      "10           17.573885   7.191224e+07                 0.774338  \n",
      "6            17.681336   7.195955e+07                 0.773440  \n",
      "2            19.051572   7.375170e+07                 0.766070  \n",
      "16           18.658950   7.560906e+07                 0.758649  \n",
      "12           18.741572   7.591465e+07                 0.757533  \n",
      "4            19.283247   7.700985e+07                 0.755153  \n",
      "8            18.973020   7.683307e+07                 0.754234  \n",
      "0            20.998224   8.620851e+07                 0.732759  \n",
      "19           23.126596   1.006669e+08                 0.707734  \n",
      "7            23.132590   9.946434e+07                 0.707727  \n",
      "15           23.128067   1.006555e+08                 0.707722  \n",
      "11           23.127722   1.005301e+08                 0.707704  \n",
      "3            23.722095   9.414337e+07                 0.703481  \n"
     ]
    }
   ],
   "source": [
    "# Cargar el Dataset\n",
    "file_path = \"DatosNacionales.csv\"  # Asegúrate de colocar la ruta correcta\n",
    "df = pd.read_csv(file_path, delimiter=\";\")\n",
    "\n",
    "# Eliminar las variables especificadas\n",
    "columns_to_exclude = [\"region\", \"titulo\", \"modelo_portada\", \"especial\", \"id\", \"fecha\", \"year\", \"subtitular\", \"cobrable\", \"envio_total\", \"devuelto\"]\n",
    "df = df.drop(columns=columns_to_exclude, errors=\"ignore\")\n",
    "\n",
    "# Lista de variables categóricas que deben ser convertidas a dummies\n",
    "categorical_vars = [\"day\", \"month\", \"contraportada\"]\n",
    "\n",
    "# Verificar qué variables categóricas existen en el dataset\n",
    "existing_categorical_vars = [col for col in categorical_vars if col in df.columns]\n",
    "\n",
    "# Convertir variables categóricas en dummies\n",
    "df = pd.get_dummies(df, columns=existing_categorical_vars, drop_first=True)\n",
    "\n",
    "# Asegurar que todas las variables sean numéricas\n",
    "df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Definir las variables predictoras (X) excluyendo \"vendido\"\n",
    "X = df.drop(columns=[\"vendido\"])\n",
    "\n",
    "# Variable objetivo (y)\n",
    "y = df[\"vendido\"]\n",
    "\n",
    "# Llenar valores NaN para evitar errores en la regresión\n",
    "X = X.fillna(X.median())  # Usando la mediana\n",
    "y = y.fillna(y.median())  # Usando la mediana\n",
    "\n",
    "# Convertir todas las variables a tipo float\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y conjunto de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir la cuadrícula de hiperparámetros: n_estimators y max_depth\n",
    "valores_n_estimators = [20, 40, 60, 80, 100]\n",
    "valores_max_depth = [5, 10, 15, 25]\n",
    "\n",
    "# Inicializar lista para almacenar resultados\n",
    "resultados = []\n",
    "\n",
    "# Iterar sobre las combinaciones de n_estimators y max_depth\n",
    "for n_estimators in valores_n_estimators:\n",
    "    for max_depth in valores_max_depth:\n",
    "        print(f\"Entrenando Gradient Boosted Trees con n_estimators={n_estimators}, max_depth={max_depth}\")\n",
    "        \n",
    "        # Crear y ajustar el modelo\n",
    "        gb_modelo = GradientBoostingRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "        gb_modelo.fit(X_train, y_train)\n",
    "        \n",
    "        # Generar predicciones\n",
    "        y_pred = gb_modelo.predict(X_test)\n",
    "        \n",
    "        # 1. Root Mean Squared Error (RMSE)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "        # 2. Absolute Error\n",
    "        absolute_error = mean_absolute_error(y_test, y_pred)\n",
    "        \n",
    "        # 3. Relative Error (Lenient)\n",
    "        relative_error = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "        \n",
    "        # 4. Squared Error\n",
    "        squared_error = np.mean((y_test - y_pred) ** 2)\n",
    "        \n",
    "        # 5. Correlation Coefficient (R)\n",
    "        correlation, _ = pearsonr(y_test, y_pred)\n",
    "        \n",
    "        # Almacenar los resultados en la lista\n",
    "        resultados.append({\n",
    "            \"Number of Trees\": n_estimators,\n",
    "            \"Maximal Depth\": max_depth,\n",
    "            \"RMSE\": rmse,\n",
    "            \"Absolute Error\": absolute_error,\n",
    "            \"Relative Error (%)\": relative_error,\n",
    "            \"Squared Error\": squared_error,\n",
    "            \"Correlation Coefficient\": correlation\n",
    "        })\n",
    "\n",
    "# Crear un DataFrame para visualizar los resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "# Ordenar el DataFrame por las métricas en orden ascendente o descendente según sea necesario\n",
    "df_resultados_ranked_rmse = df_resultados.sort_values(by=\"RMSE\", ascending=True)  # Mejor RMSE al principio\n",
    "df_resultados_ranked_absolute_error = df_resultados.sort_values(by=\"Absolute Error\", ascending=True)  # Mejor Error Absoluto al principio\n",
    "df_resultados_ranked_r2 = df_resultados.sort_values(by=\"Correlation Coefficient\", ascending=False)  # Mejor R² al principio\n",
    "\n",
    "# Mostrar los resultados ordenados en ranking para cada métrica\n",
    "print(\"\\nRanking de modelos por RMSE:\")\n",
    "print(df_resultados_ranked_rmse)\n",
    "\n",
    "print(\"\\nRanking de modelos por Error Absoluto:\")\n",
    "print(df_resultados_ranked_absolute_error)\n",
    "\n",
    "print(\"\\nRanking de modelos por R²:\")\n",
    "print(df_resultados_ranked_r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
