{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fecha</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "      <th>titulo</th>\n",
       "      <th>subtitular</th>\n",
       "      <th>cant_notas</th>\n",
       "      <th>politica</th>\n",
       "      <th>...</th>\n",
       "      <th>publicidad</th>\n",
       "      <th>contraportada</th>\n",
       "      <th>modelo</th>\n",
       "      <th>palabras_titulo</th>\n",
       "      <th>palabras_st</th>\n",
       "      <th>envio_total</th>\n",
       "      <th>cobrable</th>\n",
       "      <th>devuelto</th>\n",
       "      <th>vendido</th>\n",
       "      <th>total_paginas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010222nacional</td>\n",
       "      <td>2/1/2022</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>January</td>\n",
       "      <td>2022</td>\n",
       "      <td>nacional</td>\n",
       "      <td>celebracion lo lleva a la muerte</td>\n",
       "      <td>ya no llego a darles el abrazo a sus papas, en...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>modelo</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>94993</td>\n",
       "      <td>93185</td>\n",
       "      <td>11937</td>\n",
       "      <td>81248</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010322nacional</td>\n",
       "      <td>3/1/2022</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "      <td>2022</td>\n",
       "      <td>nacional</td>\n",
       "      <td>campeon historico</td>\n",
       "      <td>los toros suman su primer titulo de liga nacional</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>deporte</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>110810</td>\n",
       "      <td>108409</td>\n",
       "      <td>6740</td>\n",
       "      <td>101669</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>010422nacional</td>\n",
       "      <td>4/1/2022</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>January</td>\n",
       "      <td>2022</td>\n",
       "      <td>nacional</td>\n",
       "      <td>arde ensambladora</td>\n",
       "      <td>se destruyen miles de motos en amatitlan</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>nacionales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>97543</td>\n",
       "      <td>95151</td>\n",
       "      <td>8336</td>\n",
       "      <td>86815</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>010522nacional</td>\n",
       "      <td>5/1/2022</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "      <td>2022</td>\n",
       "      <td>nacional</td>\n",
       "      <td>balean albaniles</td>\n",
       "      <td>sicarios los esperaban en esquina del centro d...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>modelo</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>96234</td>\n",
       "      <td>93842</td>\n",
       "      <td>14682</td>\n",
       "      <td>79160</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010622nacional</td>\n",
       "      <td>6/1/2022</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>January</td>\n",
       "      <td>2022</td>\n",
       "      <td>nacional</td>\n",
       "      <td>feliz dia de reyes</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>modelo</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>96254</td>\n",
       "      <td>93851</td>\n",
       "      <td>9796</td>\n",
       "      <td>84055</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id     fecha        day    month  year    region  \\\n",
       "0  010222nacional  2/1/2022     Sunday  January  2022  nacional   \n",
       "1  010322nacional  3/1/2022     Monday  January  2022  nacional   \n",
       "2  010422nacional  4/1/2022    Tuesday  January  2022  nacional   \n",
       "3  010522nacional  5/1/2022  Wednesday  January  2022  nacional   \n",
       "4  010622nacional  6/1/2022   Thursday  January  2022  nacional   \n",
       "\n",
       "                             titulo  \\\n",
       "0  celebracion lo lleva a la muerte   \n",
       "1                 campeon historico   \n",
       "2                 arde ensambladora   \n",
       "3                  balean albaniles   \n",
       "4                feliz dia de reyes   \n",
       "\n",
       "                                          subtitular  cant_notas  politica  \\\n",
       "0  ya no llego a darles el abrazo a sus papas, en...           4         0   \n",
       "1  los toros suman su primer titulo de liga nacional           5         0   \n",
       "2           se destruyen miles de motos en amatitlan           4         0   \n",
       "3  sicarios los esperaban en esquina del centro d...           3         0   \n",
       "4                                                  -           1         0   \n",
       "\n",
       "   ...  publicidad  contraportada  modelo  palabras_titulo  palabras_st  \\\n",
       "0  ...           0         modelo       1                6           13   \n",
       "1  ...           1        deporte       1                2            9   \n",
       "2  ...           0     nacionales       1                2            7   \n",
       "3  ...           1         modelo       1                2           10   \n",
       "4  ...           0         modelo       1                4            1   \n",
       "\n",
       "   envio_total  cobrable  devuelto  vendido total_paginas  \n",
       "0        94993     93185     11937    81248            36  \n",
       "1       110810    108409      6740   101669            34  \n",
       "2        97543     95151      8336    86815            32  \n",
       "3        96234     93842     14682    79160            32  \n",
       "4        96254     93851      9796    84055            32  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar datos\n",
    "file_path = r'C:\\Users\\emisi\\OneDrive\\INCAE_Análisis de Datos, Innovación y Tecnología\\PAIT\\Nuestro Diario\\Bases de Datos\\Análisis de Bases de Datos\\DatosNacionales.csv'\n",
    "df = pd.read_csv(file_path, delimiter= ';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando XGBoost con n_estimators=20, max_depth=5\n",
      "Entrenando XGBoost con n_estimators=20, max_depth=10\n",
      "Entrenando XGBoost con n_estimators=20, max_depth=15\n",
      "Entrenando XGBoost con n_estimators=20, max_depth=25\n",
      "Entrenando XGBoost con n_estimators=40, max_depth=5\n",
      "Entrenando XGBoost con n_estimators=40, max_depth=10\n",
      "Entrenando XGBoost con n_estimators=40, max_depth=15\n",
      "Entrenando XGBoost con n_estimators=40, max_depth=25\n",
      "Entrenando XGBoost con n_estimators=60, max_depth=5\n",
      "Entrenando XGBoost con n_estimators=60, max_depth=10\n",
      "Entrenando XGBoost con n_estimators=60, max_depth=15\n",
      "Entrenando XGBoost con n_estimators=60, max_depth=25\n",
      "Entrenando XGBoost con n_estimators=80, max_depth=5\n",
      "Entrenando XGBoost con n_estimators=80, max_depth=10\n",
      "Entrenando XGBoost con n_estimators=80, max_depth=15\n",
      "Entrenando XGBoost con n_estimators=80, max_depth=25\n",
      "Entrenando XGBoost con n_estimators=100, max_depth=5\n",
      "Entrenando XGBoost con n_estimators=100, max_depth=10\n",
      "Entrenando XGBoost con n_estimators=100, max_depth=15\n",
      "Entrenando XGBoost con n_estimators=100, max_depth=25\n",
      "\n",
      "Resultados de XGBoost:\n",
      "    Number of Trees  Maximal Depth         RMSE  Absolute Error  \\\n",
      "5                40             10  7899.304110     5379.598649   \n",
      "9                60             10  7900.720418     5377.264027   \n",
      "13               80             10  7901.672024     5377.527368   \n",
      "17              100             10  7902.910976     5378.484456   \n",
      "8                60              5  7936.651092     5580.423417   \n",
      "16              100              5  7941.606754     5607.813767   \n",
      "1                20             10  7952.476152     5435.456099   \n",
      "12               80              5  7960.249333     5592.450688   \n",
      "4                40              5  8026.427185     5588.046980   \n",
      "0                20              5  8182.187423     5589.767546   \n",
      "19              100             25  8209.718839     5618.980505   \n",
      "15               80             25  8209.719312     5618.980489   \n",
      "11               60             25  8209.722717     5618.981921   \n",
      "7                40             25  8209.988899     5619.270681   \n",
      "3                20             25  8235.454059     5641.796617   \n",
      "10               60             15  8484.312053     5787.844755   \n",
      "6                40             15  8484.346903     5787.929490   \n",
      "18              100             15  8484.382738     5787.908239   \n",
      "14               80             15  8484.382791     5787.907001   \n",
      "2                20             15  8487.372462     5791.579533   \n",
      "\n",
      "    Relative Error (%)  Squared Error  Correlation Coefficient  \n",
      "5            10.747575   6.239901e+07                 0.805766  \n",
      "9            10.732522   6.242138e+07                 0.805679  \n",
      "13           10.735860   6.243642e+07                 0.805641  \n",
      "17           10.738883   6.245600e+07                 0.805575  \n",
      "8            14.037302   6.299043e+07                 0.803576  \n",
      "16           14.206546   6.306912e+07                 0.803307  \n",
      "1            10.891460   6.324188e+07                 0.802985  \n",
      "12           14.149355   6.336557e+07                 0.802290  \n",
      "4            13.986600   6.442353e+07                 0.798431  \n",
      "0            15.199869   6.694819e+07                 0.790790  \n",
      "19           10.218805   6.739948e+07                 0.792360  \n",
      "15           10.218791   6.739949e+07                 0.792360  \n",
      "11           10.218775   6.739955e+07                 0.792360  \n",
      "7            10.218978   6.740392e+07                 0.792343  \n",
      "3            10.486059   6.782270e+07                 0.790677  \n",
      "10           11.090033   7.198355e+07                 0.777153  \n",
      "6            11.092247   7.198414e+07                 0.777153  \n",
      "18           11.090220   7.198475e+07                 0.777149  \n",
      "14           11.090218   7.198475e+07                 0.777149  \n",
      "2            11.099167   7.203549e+07                 0.776605  \n"
     ]
    }
   ],
   "source": [
    "# Cargar el Dataset\n",
    "file_path = \"DatosNacionales.csv\"  # Asegúrate de colocar la ruta correcta\n",
    "df = pd.read_csv(file_path, delimiter=\";\")\n",
    "\n",
    "# Eliminar las variables especificadas\n",
    "columns_to_exclude = [\"region\", \"titulo\", \"modelo_portada\", \"especial\", \"id\", \"fecha\", \"year\", \"subtitular\", \"cobrable\", \"envio_total\", \"devuelto\"]\n",
    "df = df.drop(columns=columns_to_exclude, errors=\"ignore\")\n",
    "\n",
    "# Lista de variables categóricas que deben ser convertidas a dummies\n",
    "categorical_vars = [\"day\", \"month\", \"contraportada\"]\n",
    "\n",
    "# Verificar qué variables categóricas existen en el dataset\n",
    "existing_categorical_vars = [col for col in categorical_vars if col in df.columns]\n",
    "\n",
    "# Convertir variables categóricas en dummies\n",
    "df = pd.get_dummies(df, columns=existing_categorical_vars, drop_first=True)\n",
    "\n",
    "# Asegurar que todas las variables sean numéricas\n",
    "df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Definir las variables predictoras (X) excluyendo \"vendido\"\n",
    "X = df.drop(columns=[\"vendido\"])\n",
    "\n",
    "# Variable objetivo (y)\n",
    "y = df[\"vendido\"]\n",
    "\n",
    "# Llenar valores NaN para evitar errores en la regresión\n",
    "X = X.fillna(X.median())  # Usando la mediana\n",
    "y = y.fillna(y.median())  # Usando la mediana\n",
    "\n",
    "# Convertir todas las variables a tipo float\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y conjunto de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir la cuadrícula de hiperparámetros: n_estimators y max_depth\n",
    "valores_n_estimators = [20, 40, 60, 80, 100]\n",
    "valores_max_depth = [5, 10, 15, 25]\n",
    "\n",
    "# Inicializar lista para almacenar resultados\n",
    "resultados = []\n",
    "\n",
    "# Iterar sobre las combinaciones de n_estimators y max_depth\n",
    "for n_estimators in valores_n_estimators:\n",
    "    for max_depth in valores_max_depth:\n",
    "        print(f\"Entrenando XGBoost con n_estimators={n_estimators}, max_depth={max_depth}\")\n",
    "        \n",
    "        # Crear el modelo XGBoost\n",
    "        xgb_modelo = xgb.XGBRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "        xgb_modelo.fit(X_train, y_train)\n",
    "        \n",
    "        # Generar predicciones\n",
    "        y_pred = xgb_modelo.predict(X_test)\n",
    "        \n",
    "        # 1. Root Mean Squared Error (RMSE)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "        # 2. Absolute Error\n",
    "        absolute_error = mean_absolute_error(y_test, y_pred)\n",
    "        \n",
    "        # 3. Relative Error (Lenient)\n",
    "        relative_error = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "        \n",
    "        # 4. Squared Error\n",
    "        squared_error = np.mean((y_test - y_pred) ** 2)\n",
    "        \n",
    "        # 5. Correlation Coefficient (R)\n",
    "        correlation, _ = pearsonr(y_test, y_pred)\n",
    "        \n",
    "        # Almacenar los resultados en la lista\n",
    "        resultados.append({\n",
    "            \"Number of Trees\": n_estimators,\n",
    "            \"Maximal Depth\": max_depth,\n",
    "            \"RMSE\": rmse,\n",
    "            \"Absolute Error\": absolute_error,\n",
    "            \"Relative Error (%)\": relative_error,\n",
    "            \"Squared Error\": squared_error,\n",
    "            \"Correlation Coefficient\": correlation\n",
    "        })\n",
    "\n",
    "# Crear un DataFrame para visualizar los resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "# Mostrar los resultados ordenados por las métricas más importantes\n",
    "df_resultados_sorted = df_resultados.sort_values(by=[\"RMSE\", \"Absolute Error\", \"Correlation Coefficient\"], ascending=[True, True, False])\n",
    "\n",
    "# Imprimir la tabla de resultados ordenados\n",
    "print(\"\\nResultados de XGBoost:\")\n",
    "print(df_resultados_sorted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
